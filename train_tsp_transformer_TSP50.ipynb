{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Transformer Network for the Traveling Salesman Problem\n",
    "\n",
    "Xavier Bresson, Thomas Laurent, Feb 2021<br>\n",
    "\n",
    "Arxiv : https://arxiv.org/pdf/2103.03012.pdf<br>\n",
    "Talk : https://ipam.wistia.com/medias/0jrweluovs<br>\n",
    "Slides : https://t.co/ySxGiKtQL5<br>\n",
    "\n",
    "This code trains the transformer network by reinforcement learning.<br>\n",
    "Use the beam search code to test the trained network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1565913/3786564012.py:22: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('png2x','pdf')\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# Libs\n",
    "###################\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# visualization \n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats, clear_output\n",
    "set_matplotlib_formats('png2x','pdf')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "try: \n",
    "    import networkx as nx\n",
    "    from scipy.spatial.distance import pdist, squareform\n",
    "    from concorde.tsp import TSPSolver # !pip install -e pyconcorde\n",
    "except:\n",
    "    print(\"Fail to import concorde.tsp\")\n",
    "    pass\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name: NVIDIA RTX A6000, gpu_id: 1\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# Hardware : CPU / GPU(s)\n",
    "###################\n",
    "\n",
    "device = torch.device(\"cpu\"); gpu_id = -1 # select CPU\n",
    "\n",
    "gpu_id = '1' # select a single GPU  \n",
    "#gpu_id = '2,3' # select multiple GPUs  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU name: {:s}, gpu_id: {:s}'.format(torch.cuda.get_device_name(0),gpu_id))   \n",
    "    \n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nb_nodes': 50, 'bsz': 512, 'dim_emb': 128, 'dim_ff': 512, 'dim_input_nodes': 2, 'nb_layers_encoder': 6, 'nb_layers_decoder': 2, 'nb_heads': 8, 'nb_epochs': 10000, 'nb_batch_per_epoch': 2500, 'nb_batch_eval': 20, 'gpu_id': '1', 'lr': 0.0001, 'tol': 0.001, 'batchnorm': True, 'max_len_PE': 1000}\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# Hyper-parameters\n",
    "###################\n",
    "\n",
    "class DotDict(dict):\n",
    "    def __init__(self, **kwds):\n",
    "        self.update(kwds)\n",
    "        self.__dict__ = self\n",
    "        \n",
    "args = DotDict()\n",
    "args.nb_nodes = 20 # TSP20\n",
    "args.nb_nodes = 50 # TSP50\n",
    "#args.nb_nodes = 100 # TSP100\n",
    "args.bsz = 512 # TSP20 TSP50\n",
    "args.dim_emb = 128\n",
    "args.dim_ff = 512\n",
    "args.dim_input_nodes = 2\n",
    "args.nb_layers_encoder = 6\n",
    "args.nb_layers_decoder = 2\n",
    "args.nb_heads = 8\n",
    "args.nb_epochs = 10000\n",
    "args.nb_batch_per_epoch = 2500\n",
    "args.nb_batch_eval = 20\n",
    "args.gpu_id = gpu_id\n",
    "args.lr = 1e-4\n",
    "args.tol = 1e-3\n",
    "args.batchnorm = True  # if batchnorm=True  than batch norm is used\n",
    "#args.batchnorm = False # if batchnorm=False than layer norm is used\n",
    "args.max_len_PE = 1000\n",
    "\n",
    "print(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'nb_nodes': 50, 'bsz': 512, 'dim_emb': 128, 'dim_ff': 512, 'dim_input_nodes': 2, 'nb_layers_encoder': 6, 'nb_layers_decoder': 2, 'nb_heads': 8, 'nb_epochs': 10000, 'nb_batch_per_epoch': 2500, 'nb_batch_eval': 20, 'gpu_id': '1', 'lr': 0.0001, 'tol': 0.001, 'batchnorm': True, 'max_len_PE': 1000}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘logs’: File exists\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Size does not match at dimension 2 expected index [512, 50, 50] to be smaller than self [512, 50, 1] apart from dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.150.240.105/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=333'>334</a>\u001b[0m \u001b[39m###################\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.150.240.105/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=334'>335</a>\u001b[0m \u001b[39m# Train model for one epoch\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.150.240.105/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=335'>336</a>\u001b[0m \u001b[39m###################\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.150.240.105/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=336'>337</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B10.150.240.105/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=338'>339</a>\u001b[0m loss, loss_class, loss_box \u001b[39m=\u001b[39m train_one_epoch(model, train_dataloader, optimizer, device)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.150.240.105/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=339'>340</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m, Loss Class: \u001b[39m\u001b[39m{\u001b[39;00mloss_class\u001b[39m}\u001b[39;00m\u001b[39m, Loss Box: \u001b[39m\u001b[39m{\u001b[39;00mloss_box\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.150.240.105/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=341'>342</a>\u001b[0m time_one_epoch \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start\n",
      "\u001b[1;32m/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.150.240.105/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=310'>311</a>\u001b[0m         matched_idx_list\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mtensor(matched_idx, device\u001b[39m=\u001b[39mdevice))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.150.240.105/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=312'>313</a>\u001b[0m matched_idx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(matched_idx_list)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B10.150.240.105/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=314'>315</a>\u001b[0m loss, loss_class, loss_box \u001b[39m=\u001b[39m custom_loss(output_class, output_box, label_class, data, matched_idx)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.150.240.105/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=316'>317</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.150.240.105/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=317'>318</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[1;32m/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.150.240.105/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=274'>275</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcustom_loss\u001b[39m(output_class, output_box, label_class, label_box, matched_idx):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.150.240.105/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=276'>277</a>\u001b[0m     matched_output_box \u001b[39m=\u001b[39m label_box\u001b[39m.\u001b[39mgather(\u001b[39m1\u001b[39m, matched_idx\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mexpand(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, output_box\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)))\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B10.150.240.105/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=277'>278</a>\u001b[0m     matched_output_class \u001b[39m=\u001b[39m label_class\u001b[39m.\u001b[39;49mgather(\u001b[39m1\u001b[39;49m, matched_idx\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mexpand(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, output_class\u001b[39m.\u001b[39;49msize(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.150.240.105/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=279'>280</a>\u001b[0m     loss_class \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(output_class\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m), matched_output_class\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.150.240.105/home/xianliang/yifan/TSP_Transformer/train_tsp_transformer_TSP50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=281'>282</a>\u001b[0m     loss_box \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(output_box, matched_output_box)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Size does not match at dimension 2 expected index [512, 50, 50] to be smaller than self [512, 50, 1] apart from dimension 1"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# Network definition\n",
    "# Notation : \n",
    "#            bsz : batch size\n",
    "#            nb_nodes : number of nodes/cities\n",
    "#            dim_emb : embedding/hidden dimension\n",
    "#            nb_heads : nb of attention heads\n",
    "#            dim_ff : feed-forward dimension\n",
    "#            nb_layers : number of encoder/decoder layers\n",
    "###################\n",
    "def compute_tour_length(x, tour): \n",
    "    \"\"\"\n",
    "    Compute the length of a batch of tours\n",
    "    Inputs : x of size (bsz, nb_nodes, 2) batch of tsp tour instances\n",
    "             tour of size (bsz, nb_nodes) batch of sequences (node indices) of tsp tours\n",
    "    Output : L of size (bsz,)             batch of lengths of each tsp tour\n",
    "    \"\"\"\n",
    "    bsz = x.shape[0]\n",
    "    nb_nodes = x.shape[1]\n",
    "    arange_vec = torch.arange(bsz, device=x.device)\n",
    "    first_cities = x[arange_vec, tour[:,0], :] # size(first_cities)=(bsz,2)\n",
    "    previous_cities = first_cities\n",
    "    L = torch.zeros(bsz, device=x.device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(1,nb_nodes):\n",
    "            current_cities = x[arange_vec, tour[:,i], :] \n",
    "            L += torch.sum( (current_cities - previous_cities)**2 , dim=1 )**0.5 # dist(current, previous node) \n",
    "            previous_cities = current_cities\n",
    "        L += torch.sum( (current_cities - first_cities)**2 , dim=1 )**0.5 # dist(last, first node)  \n",
    "    return L\n",
    "\n",
    "\n",
    "class Transformer_encoder_net(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder network based on self-attention transformer\n",
    "    Inputs :  \n",
    "      h of size      (bsz, nb_nodes+1, dim_emb)    batch of input cities\n",
    "    Outputs :  \n",
    "      h of size      (bsz, nb_nodes+1, dim_emb)    batch of encoded cities\n",
    "      score of size  (bsz, nb_nodes+1, nb_nodes+1) batch of attention scores\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_layers, dim_emb, nb_heads, dim_ff, batchnorm):\n",
    "        super(Transformer_encoder_net, self).__init__()\n",
    "        assert dim_emb == nb_heads* (dim_emb//nb_heads) # check if dim_emb is divisible by nb_heads\n",
    "        self.MHA_layers = nn.ModuleList( [nn.MultiheadAttention(dim_emb, nb_heads) for _ in range(nb_layers)] )\n",
    "        self.linear1_layers = nn.ModuleList( [nn.Linear(dim_emb, dim_ff) for _ in range(nb_layers)] )\n",
    "        self.linear2_layers = nn.ModuleList( [nn.Linear(dim_ff, dim_emb) for _ in range(nb_layers)] )   \n",
    "        if batchnorm:\n",
    "            self.norm1_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n",
    "            self.norm2_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n",
    "        else:\n",
    "            self.norm1_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n",
    "            self.norm2_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n",
    "        self.nb_layers = nb_layers\n",
    "        self.nb_heads = nb_heads\n",
    "        self.batchnorm = batchnorm\n",
    "        \n",
    "    def forward(self, h):      \n",
    "        # PyTorch nn.MultiheadAttention requires input size (seq_len, bsz, dim_emb) \n",
    "        h = h.transpose(0,1) # size(h)=(nb_nodes, bsz, dim_emb)  \n",
    "        # L layers\n",
    "        for i in range(self.nb_layers):\n",
    "            h_rc = h # residual connection, size(h_rc)=(nb_nodes, bsz, dim_emb)\n",
    "            h, score = self.MHA_layers[i](h, h, h) # size(h)=(nb_nodes, bsz, dim_emb), size(score)=(bsz, nb_nodes, nb_nodes)\n",
    "            # add residual connection\n",
    "            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            if self.batchnorm:\n",
    "                # Pytorch nn.BatchNorm1d requires input size (bsz, dim, seq_len)\n",
    "                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = self.norm1_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            else:\n",
    "                h = self.norm1_layers[i](h)       # size(h)=(nb_nodes, bsz, dim_emb) \n",
    "            # feedforward\n",
    "            h_rc = h # residual connection\n",
    "            h = self.linear2_layers[i](torch.relu(self.linear1_layers[i](h)))\n",
    "            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            if self.batchnorm:\n",
    "                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = self.norm2_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            else:\n",
    "                h = self.norm2_layers[i](h) # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "        # Transpose h\n",
    "        h = h.transpose(0,1) # size(h)=(bsz, nb_nodes, dim_emb)\n",
    "        return h, score\n",
    "    \n",
    "\n",
    "class Transformer_decoder_net(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder network based on self-attention transformer\n",
    "    Inputs :  \n",
    "      h of size      (bsz, nb_nodes+1, dim_emb)    batch of input cities\n",
    "    Outputs :  \n",
    "      h of size      (bsz, nb_nodes+1, dim_emb)    batch of encoded cities\n",
    "      score of size  (bsz, nb_nodes+1, nb_nodes+1) batch of attention scores\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_layers, dim_emb, nb_heads, dim_ff, batchnorm):\n",
    "        super(Transformer_decoder_net, self).__init__()\n",
    "        assert dim_emb == nb_heads* (dim_emb//nb_heads) # check if dim_emb is divisible by nb_heads\n",
    "        self.MHA_layers = nn.ModuleList( [nn.MultiheadAttention(dim_emb, nb_heads) for _ in range(nb_layers)] )\n",
    "        self.CRS_layers = nn.ModuleList( [nn.MultiheadAttention(dim_emb, nb_heads) for _ in range(nb_layers)] )\n",
    "\n",
    "        if batchnorm:\n",
    "            self.norm1_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n",
    "            self.norm2_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n",
    "            self.norm3_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n",
    "        else:\n",
    "            self.norm1_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n",
    "            self.norm2_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n",
    "            self.norm3_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n",
    "        \n",
    "        self.linear1_layers = nn.ModuleList( [nn.Linear(dim_emb, dim_ff) for _ in range(nb_layers)] )\n",
    "        self.linear2_layers = nn.ModuleList( [nn.Linear(dim_ff, dim_emb) for _ in range(nb_layers)] )   \n",
    "        self.nb_layers = nb_layers\n",
    "        self.nb_heads = nb_heads\n",
    "        self.batchnorm = batchnorm\n",
    "        \n",
    "    def forward(self, q, k, v):      \n",
    "        # PyTorch nn.MultiheadAttention requires input size (seq_len, bsz, dim_emb) \n",
    "        q = q.transpose(0,1) # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "        k = k.transpose(0,1)\n",
    "        v = v.transpose(0,1)\n",
    "        # L layers\n",
    "        for i in range(self.nb_layers):\n",
    "            q_rc = q # residual connection, size(h_rc)=(nb_nodes, bsz, dim_emb)\n",
    "            q, score = self.MHA_layers[i](q, q, q) # size(h)=(nb_nodes, bsz, dim_emb), size(score)=(bsz, nb_nodes, nb_nodes)\n",
    "            # add residual connection\n",
    "            q = q_rc + q # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            if self.batchnorm:\n",
    "                # Pytorch nn.BatchNorm1d requires input size (bsz, dim, seq_len)\n",
    "                q = q.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                q = self.norm1_layers[i](q)       # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                q = q.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            else:\n",
    "                q = self.norm1_layers[i](q)       # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "\n",
    "            q_rc = q\n",
    "            q, score = self.CRS_layers[i](q, k, v)\n",
    "            q = q_rc + q # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            if self.batchnorm:\n",
    "                # Pytorch nn.BatchNorm1d requires input size (bsz, dim, seq_len)\n",
    "                q = q.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                q = self.norm2_layers[i](q)       # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                q = q.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            else:\n",
    "                q = self.norm2_layers[i](q)       # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            \n",
    "            # feedforward\n",
    "            q_rc = q # residual connection\n",
    "            q = self.linear2_layers[i](torch.relu(self.linear1_layers[i](q)))\n",
    "            q = q_rc + q # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            if self.batchnorm:\n",
    "                q = q.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                q = self.norm3_layers[i](q)       # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                q = q.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            else:\n",
    "                q = self.norm3_layers[i](q) # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "        # Transpose h\n",
    "        q = q.transpose(0,1) # size(h)=(bsz, nb_nodes, dim_emb)\n",
    "        return q, score\n",
    "    \n",
    "    \n",
    "class TSP_net(nn.Module): \n",
    "    \n",
    "    def __init__(self, dim_input_nodes, dim_emb, dim_ff, \n",
    "                 nb_layers_encoder, nb_heads, batchnorm=True):\n",
    "        super(TSP_net, self).__init__()\n",
    "        \n",
    "        self.dim_emb = dim_emb\n",
    "        \n",
    "        # input embedding layer\n",
    "        self.input_emb = nn.Linear(dim_input_nodes, dim_emb)\n",
    "        \n",
    "        # encoder layer\n",
    "        self.encoder = Transformer_encoder_net(nb_layers_encoder, dim_emb, nb_heads, dim_ff, batchnorm)\n",
    "\n",
    "        self.decoder = Transformer_decoder_net(nb_layers_encoder, dim_emb, nb_heads, dim_ff, batchnorm)\n",
    "\n",
    "        self.query_box = nn.Parameter(torch.randn(50, dim_emb))\n",
    "\n",
    "        self.linear_class = nn.Linear(dim_emb, 50)\n",
    "        self.linear_box = nn.Linear(dim_emb, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # input embedding layer\n",
    "        h = self.input_emb(x) # size(h)=(bsz, nb_nodes, dim_emb)\n",
    "        \n",
    "        # encoder layer\n",
    "        h_encoder, _ = self.encoder(h) # size(h)=(bsz, nb_nodes, dim_emb)\n",
    "\n",
    "        h_decoder, _ = self.decoder(self.query_box.unsqueeze(0).expand(x.size(0), -1, -1), h_encoder, h_encoder)\n",
    "\n",
    "        return self.linear_class(h_decoder), self.linear_box(h_decoder)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "model = TSP_net(args.dim_input_nodes, args.dim_emb, args.dim_ff, \n",
    "              args.nb_layers_encoder, args.nb_heads, batchnorm=args.batchnorm)\n",
    "\n",
    "model_baseline = TSP_net(args.dim_input_nodes, args.dim_emb, args.dim_ff, \n",
    "              args.nb_layers_encoder, args.nb_heads, batchnorm=args.batchnorm)\n",
    "\n",
    "# uncomment these lines if trained with multiple GPUs\n",
    "print(torch.cuda.device_count())\n",
    "if torch.cuda.device_count()>1:\n",
    "    model = nn.DataParallel(model)\n",
    "    model_baseline = nn.DataParallel(model_baseline)\n",
    "# uncomment these lines if trained with multiple GPUs\n",
    "\n",
    "optimizer = torch.optim.Adam( model.parameters() , lr = args.lr ) \n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "print(args); print('')\n",
    "\n",
    "# Logs\n",
    "os.system(\"mkdir logs\")\n",
    "time_stamp=datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\")\n",
    "file_name = 'logs'+'/'+time_stamp + \"-n{}\".format(args.nb_nodes) + \"-gpu{}\".format(args.gpu_id) + \".txt\"\n",
    "file = open(file_name,\"w\",1) \n",
    "file.write(time_stamp+'\\n\\n') \n",
    "for arg in vars(args):\n",
    "    file.write(arg)\n",
    "    hyper_param_val=\"={}\".format(getattr(args, arg))\n",
    "    file.write(hyper_param_val)\n",
    "    file.write('\\n')\n",
    "file.write('\\n\\n') \n",
    "plot_performance_train = []\n",
    "all_strings = []\n",
    "epoch_ckpt = 0\n",
    "tot_time_ckpt = 0\n",
    "\n",
    "\n",
    "# # Uncomment these lines to re-start training with saved checkpoint\n",
    "# checkpoint_file = \"checkpoint/checkpoint_21-03-01--17-25-00-n50-gpu0.pkl\"\n",
    "# checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "# epoch_ckpt = checkpoint['epoch'] + 1\n",
    "# tot_time_ckpt = checkpoint['tot_time']\n",
    "# plot_performance_train = checkpoint['plot_performance_train']\n",
    "# plot_performance_baseline = checkpoint['plot_performance_baseline']\n",
    "# model_baseline.load_state_dict(checkpoint['model_baseline'])\n",
    "# model.load_state_dict(checkpoint['model'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "# print('Re-start training with saved checkpoint file={:s}\\n  Checkpoint at epoch= {:d} and time={:.3f}min\\n'.format(checkpoint_file,epoch_ckpt-1,tot_time_ckpt/60))\n",
    "# del checkpoint\n",
    "# # Uncomment these lines to re-start training with saved checkpoint\n",
    "\n",
    "\n",
    "class TSPDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.data, self.label = torch.load(data_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.label[idx], dtype=torch.long)\n",
    "        return data, label\n",
    "\n",
    "\n",
    "train_data_path = \"./train_data_50.pth\"\n",
    "val_data_path = \"./val_data_50.pth\"\n",
    "\n",
    "train_dataset = TSPDataset(train_data_path)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "val_dataset = TSPDataset(val_data_path)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "def custom_loss(output_class, output_box, label_class, label_box, matched_idx):\n",
    "\n",
    "    matched_output_box = label_box.gather(1, matched_idx.unsqueeze(-1).expand(-1, -1, label_box.size(-1)))\n",
    "    matched_output_class = label_class.gather(1, matched_idx.unsqueeze(-1).expand(-1, -1, label_class.size(-1)))\n",
    "\n",
    "    loss_class = F.cross_entropy(output_class.transpose(1, 2), matched_output_class.squeeze(-1))\n",
    "\n",
    "    loss_box = F.mse_loss(output_box, matched_output_box)\n",
    "\n",
    "    loss = loss_class + loss_box\n",
    "    return loss, loss_class, loss_box\n",
    "\n",
    "###################\n",
    "# Main training loop \n",
    "###################\n",
    "start_training_time = time.time()\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_loss_class = 0.0\n",
    "    total_loss_box = 0.0\n",
    "    for data, label_class in dataloader:\n",
    "        data = data.to(device)\n",
    "        label_class = label_class.to(device)\n",
    "\n",
    "        output_class, output_box = model(data)\n",
    "\n",
    "        batch_size = data.size(0)\n",
    "        matched_idx_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(batch_size):\n",
    "                cost_matrix = torch.norm(output_box[i, None, :, :] - data[i, :, None, :], dim=2)\n",
    "                cost_matrix = cost_matrix.cpu().numpy()\n",
    "                _, matched_idx = linear_sum_assignment(cost_matrix)\n",
    "                matched_idx_list.append(torch.tensor(matched_idx, device=device))\n",
    "\n",
    "        matched_idx = torch.stack(matched_idx_list)\n",
    "\n",
    "        loss, loss_class, loss_box = custom_loss(output_class, output_box, label_class, data, matched_idx)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_loss_class += loss_class.item()\n",
    "        total_loss_box += loss_box.item()\n",
    "\n",
    "    return total_loss / len(dataloader), total_loss_class / len(dataloader), total_loss_box / len(dataloader)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(0,args.nb_epochs):\n",
    "    \n",
    "    # re-start training with saved checkpoint\n",
    "    epoch += epoch_ckpt\n",
    "\n",
    "    ###################\n",
    "    # Train model for one epoch\n",
    "    ###################\n",
    "    start = time.time()\n",
    "\n",
    "    loss, loss_class, loss_box = train_one_epoch(model, train_dataloader, optimizer, device)\n",
    "    print(f'Epoch {epoch}, Loss: {loss}, Loss Class: {loss_class}, Loss Box: {loss_box}')\n",
    "        \n",
    "    time_one_epoch = time.time() - start\n",
    "    time_tot = time.time() - start_training_time + tot_time_ckpt\n",
    "\n",
    "        \n",
    "    ###################\n",
    "    # Evaluate train model and baseline on 10k random TSP instances\n",
    "    ###################\n",
    "    def compute_tsp_length(points):\n",
    "        if points.dim() == 2:\n",
    "            points = points.unsqueeze(0)\n",
    "        length = torch.norm(points[:, :-1] - points[:, 1:], dim=-1).sum(dim=-1)\n",
    "        length += torch.norm(points[:, -1] - points[:, 0], dim=-1)\n",
    "        return length\n",
    "\n",
    "    def evaluate(model, val_dataloader):\n",
    "        total_length = 0.0\n",
    "        total_samples = 0\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, _ in val_dataloader:\n",
    "                data = data.to(device)\n",
    "                output_class, output_box = model(data)\n",
    "\n",
    "                for i in range(len(data)):\n",
    "                    cost_matrix = torch.norm(output_box[i, None, :, :] - data[i, :, None, :], dim=2)\n",
    "                    _, col_idx = linear_sum_assignment(cost_matrix.cpu().numpy())\n",
    "                    col_idx = torch.tensor(col_idx).to(device)\n",
    "                    matched_points = torch.index_select(data[i], 0, col_idx)\n",
    "\n",
    "                    order_probs = torch.nn.functional.softmax(output_class[i], dim=-1)\n",
    "                    order_cost_matrix = -order_probs\n",
    "                    _, order = linear_sum_assignment(order_cost_matrix.cpu().numpy())\n",
    "                    order = torch.tensor(order).to(device)\n",
    "                    sorted_points = torch.index_select(matched_points, 0, order)\n",
    "                    \n",
    "                    tsp_length = compute_tsp_length(sorted_points).item()\n",
    "                    total_length += tsp_length\n",
    "                    \n",
    "                total_samples += len(data)\n",
    "\n",
    "        average_length = total_length / total_samples\n",
    "        return average_length\n",
    "\n",
    "    average_length = evaluate(model, val_dataloader)\n",
    "    # For checkpoint\n",
    "    plot_performance_train.append([ (epoch+1), average_length])\n",
    "        \n",
    "    # Compute optimality gap\n",
    "    if args.nb_nodes==50: gap_train = average_length/5.692- 1.0\n",
    "    elif args.nb_nodes==100: gap_train = average_length/7.765- 1.0\n",
    "    else: gap_train = -1.0\n",
    "    \n",
    "    # Print and save in txt file\n",
    "    mystring_min = 'Epoch: {:d}, epoch time: {:.3f}min, tot time: {:.3f}day, L_train: {:.3f}, gap_train(%): {:.3f}'.format(\n",
    "        epoch, time_one_epoch/60, time_tot/86400, average_length, 100*gap_train) \n",
    "    print(mystring_min) # Comment if plot display\n",
    "    file.write(mystring_min+'\\n')\n",
    "#     all_strings.append(mystring_min) # Uncomment if plot display\n",
    "#     for string in all_strings: \n",
    "#         print(string)\n",
    "    \n",
    "    # Saving checkpoint\n",
    "    checkpoint_dir = os.path.join(\"checkpoint\")\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'time': time_one_epoch,\n",
    "        'tot_time': time_tot,\n",
    "        'loss': loss.item(),\n",
    "        'plot_performance_train': plot_performance_train,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        }, '{}.pkl'.format(checkpoint_dir + \"/checkpoint_\" + time_stamp + \"-n{}\".format(args.nb_nodes) + \"-gpu{}\".format(args.gpu_id)))\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
