{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Transformer Network for the Traveling Salesman Problem\n",
    "\n",
    "Xavier Bresson, Thomas Laurent, Feb 2021<br>\n",
    "\n",
    "Arxiv : https://arxiv.org/pdf/2103.03012.pdf<br>\n",
    "Talk : https://ipam.wistia.com/medias/0jrweluovs<br>\n",
    "Slides : https://t.co/ySxGiKtQL5<br>\n",
    "\n",
    "This code trains the transformer network by reinforcement learning.<br>\n",
    "Use the beam search code to test the trained network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4068474/1279469494.py:18: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('png2x','pdf')\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# Libs\n",
    "###################\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# visualization \n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats, clear_output\n",
    "set_matplotlib_formats('png2x','pdf')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "try: \n",
    "    import networkx as nx\n",
    "    from scipy.spatial.distance import pdist, squareform\n",
    "    from concorde.tsp import TSPSolver # !pip install -e pyconcorde\n",
    "except:\n",
    "    print(\"Fail to import concorde.tsp\")\n",
    "    pass\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name: NVIDIA RTX A6000, gpu_id: 1\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# Hardware : CPU / GPU(s)\n",
    "###################\n",
    "\n",
    "device = torch.device(\"cpu\"); gpu_id = -1 # select CPU\n",
    "\n",
    "gpu_id = '1' # select a single GPU  \n",
    "#gpu_id = '2,3' # select multiple GPUs  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU name: {:s}, gpu_id: {:s}'.format(torch.cuda.get_device_name(0),gpu_id))   \n",
    "    \n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nb_nodes': 50, 'bsz': 512, 'dim_emb': 128, 'dim_ff': 512, 'dim_input_nodes': 2, 'nb_layers_encoder': 6, 'nb_layers_decoder': 2, 'nb_heads': 8, 'nb_epochs': 10000, 'nb_batch_per_epoch': 2500, 'nb_batch_eval': 20, 'gpu_id': '1', 'lr': 0.0001, 'tol': 0.001, 'batchnorm': True, 'max_len_PE': 1000}\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# Hyper-parameters\n",
    "###################\n",
    "\n",
    "class DotDict(dict):\n",
    "    def __init__(self, **kwds):\n",
    "        self.update(kwds)\n",
    "        self.__dict__ = self\n",
    "        \n",
    "args = DotDict()\n",
    "args.nb_nodes = 20 # TSP20\n",
    "args.nb_nodes = 50 # TSP50\n",
    "#args.nb_nodes = 100 # TSP100\n",
    "args.bsz = 512 # TSP20 TSP50\n",
    "args.dim_emb = 128\n",
    "args.dim_ff = 512\n",
    "args.dim_input_nodes = 2\n",
    "args.nb_layers_encoder = 6\n",
    "args.nb_layers_decoder = 2\n",
    "args.nb_heads = 8\n",
    "args.nb_epochs = 10000\n",
    "args.nb_batch_per_epoch = 2500\n",
    "args.nb_batch_eval = 20\n",
    "args.gpu_id = gpu_id\n",
    "args.lr = 1e-4\n",
    "args.tol = 1e-3\n",
    "args.batchnorm = True  # if batchnorm=True  than batch norm is used\n",
    "#args.batchnorm = False # if batchnorm=False than layer norm is used\n",
    "args.max_len_PE = 1000\n",
    "\n",
    "print(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb of nodes : 50\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# Small test set for quick algorithm comparison\n",
    "# Note : this can be removed\n",
    "###################\n",
    "\n",
    "save_1000tsp = True\n",
    "save_1000tsp = False\n",
    "if save_1000tsp:\n",
    "    bsz = 1000\n",
    "    x = torch.rand(bsz, args.nb_nodes, args.dim_input_nodes, device='cpu') \n",
    "    print(x.size(),x[0])\n",
    "    data_dir = os.path.join(\"data\")\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    if args.nb_nodes==20 : torch.save({ 'x': x, }, '{}.pkl'.format(data_dir + \"/1000tsp20\"))\n",
    "    if args.nb_nodes==50 : torch.save({ 'x': x, }, '{}.pkl'.format(data_dir + \"/1000tsp50\"))\n",
    "    if args.nb_nodes==100 : torch.save({ 'x': x, }, '{}.pkl'.format(data_dir + \"/1000tsp100\"))\n",
    "\n",
    "checkpoint = None\n",
    "if args.nb_nodes==20 : checkpoint = torch.load(\"data/1000tsp20.pkl\")\n",
    "if args.nb_nodes==50 : checkpoint = torch.load(\"data/1000tsp50.pkl\")\n",
    "if args.nb_nodes==100 : checkpoint = torch.load(\"data/1000tsp100.pkl\")\n",
    "if checkpoint is not None:\n",
    "    x_1000tsp = checkpoint['x'].to(device)\n",
    "    n = x_1000tsp.size(1)\n",
    "    print('nb of nodes :',n)\n",
    "else:\n",
    "    x_1000tsp = torch.rand(1000, args.nb_nodes, args.dim_input_nodes, device='cpu')\n",
    "    n = x_1000tsp.size(1)\n",
    "    print('nb of nodes :',n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'nb_nodes': 50, 'bsz': 512, 'dim_emb': 128, 'dim_ff': 512, 'dim_input_nodes': 2, 'nb_layers_encoder': 6, 'nb_layers_decoder': 2, 'nb_heads': 8, 'nb_epochs': 10000, 'nb_batch_per_epoch': 2500, 'nb_batch_eval': 20, 'gpu_id': '1', 'lr': 0.0001, 'tol': 0.001, 'batchnorm': True, 'max_len_PE': 1000}\n",
      "\n",
      "Epoch: 0, epoch time: 14.097min, tot time: 0.010day, L_train: 6.899, L_base: 16.073, L_test: 6.932, gap_train(%): 21.198, update: True\n",
      "Epoch: 1, epoch time: 14.152min, tot time: 0.020day, L_train: 6.211, L_base: 6.899, L_test: 6.240, gap_train(%): 9.111, update: True\n",
      "Epoch: 2, epoch time: 14.154min, tot time: 0.030day, L_train: 6.047, L_base: 6.218, L_test: 6.065, gap_train(%): 6.234, update: True\n",
      "Epoch: 3, epoch time: 14.104min, tot time: 0.039day, L_train: 5.983, L_base: 6.048, L_test: 6.000, gap_train(%): 5.119, update: True\n",
      "Epoch: 4, epoch time: 14.087min, tot time: 0.049day, L_train: 5.946, L_base: 5.980, L_test: 5.969, gap_train(%): 4.467, update: True\n",
      "Epoch: 5, epoch time: 14.134min, tot time: 0.059day, L_train: 5.934, L_base: 5.948, L_test: 5.952, gap_train(%): 4.244, update: True\n",
      "Epoch: 6, epoch time: 14.127min, tot time: 0.069day, L_train: 5.921, L_base: 5.931, L_test: 5.942, gap_train(%): 4.015, update: True\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "###################\n",
    "# Network definition\n",
    "# Notation : \n",
    "#            bsz : batch size\n",
    "#            nb_nodes : number of nodes/cities\n",
    "#            dim_emb : embedding/hidden dimension\n",
    "#            nb_heads : nb of attention heads\n",
    "#            dim_ff : feed-forward dimension\n",
    "#            nb_layers : number of encoder/decoder layers\n",
    "###################\n",
    "def compute_tour_length(x, tour): \n",
    "    \"\"\"\n",
    "    Compute the length of a batch of tours\n",
    "    Inputs : x of size (bsz, nb_nodes, 2) batch of tsp tour instances\n",
    "             tour of size (bsz, nb_nodes) batch of sequences (node indices) of tsp tours\n",
    "    Output : L of size (bsz,)             batch of lengths of each tsp tour\n",
    "    \"\"\"\n",
    "    bsz = x.shape[0]\n",
    "    nb_nodes = x.shape[1]\n",
    "    arange_vec = torch.arange(bsz, device=x.device)\n",
    "    first_cities = x[arange_vec, tour[:,0], :] # size(first_cities)=(bsz,2)\n",
    "    previous_cities = first_cities\n",
    "    L = torch.zeros(bsz, device=x.device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(1,nb_nodes):\n",
    "            current_cities = x[arange_vec, tour[:,i], :] \n",
    "            L += torch.sum( (current_cities - previous_cities)**2 , dim=1 )**0.5 # dist(current, previous node) \n",
    "            previous_cities = current_cities\n",
    "        L += torch.sum( (current_cities - first_cities)**2 , dim=1 )**0.5 # dist(last, first node)  \n",
    "    return L\n",
    "\n",
    "\n",
    "class Transformer_encoder_net(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder network based on self-attention transformer\n",
    "    Inputs :  \n",
    "      h of size      (bsz, nb_nodes+1, dim_emb)    batch of input cities\n",
    "    Outputs :  \n",
    "      h of size      (bsz, nb_nodes+1, dim_emb)    batch of encoded cities\n",
    "      score of size  (bsz, nb_nodes+1, nb_nodes+1) batch of attention scores\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_layers, dim_emb, nb_heads, dim_ff, batchnorm):\n",
    "        super(Transformer_encoder_net, self).__init__()\n",
    "        assert dim_emb == nb_heads* (dim_emb//nb_heads) # check if dim_emb is divisible by nb_heads\n",
    "        self.MHA_layers = nn.ModuleList( [nn.MultiheadAttention(dim_emb, nb_heads) for _ in range(nb_layers)] )\n",
    "        self.linear1_layers = nn.ModuleList( [nn.Linear(dim_emb, dim_ff) for _ in range(nb_layers)] )\n",
    "        self.linear2_layers = nn.ModuleList( [nn.Linear(dim_ff, dim_emb) for _ in range(nb_layers)] )   \n",
    "        if batchnorm:\n",
    "            self.norm1_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n",
    "            self.norm2_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n",
    "        else:\n",
    "            self.norm1_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n",
    "            self.norm2_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n",
    "        self.nb_layers = nb_layers\n",
    "        self.nb_heads = nb_heads\n",
    "        self.batchnorm = batchnorm\n",
    "        \n",
    "    def forward(self, h):      \n",
    "        # PyTorch nn.MultiheadAttention requires input size (seq_len, bsz, dim_emb) \n",
    "        h = h.transpose(0,1) # size(h)=(nb_nodes, bsz, dim_emb)  \n",
    "        # L layers\n",
    "        for i in range(self.nb_layers):\n",
    "            h_rc = h # residual connection, size(h_rc)=(nb_nodes, bsz, dim_emb)\n",
    "            h, score = self.MHA_layers[i](h, h, h) # size(h)=(nb_nodes, bsz, dim_emb), size(score)=(bsz, nb_nodes, nb_nodes)\n",
    "            # add residual connection\n",
    "            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            if self.batchnorm:\n",
    "                # Pytorch nn.BatchNorm1d requires input size (bsz, dim, seq_len)\n",
    "                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = self.norm1_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            else:\n",
    "                h = self.norm1_layers[i](h)       # size(h)=(nb_nodes, bsz, dim_emb) \n",
    "            # feedforward\n",
    "            h_rc = h # residual connection\n",
    "            h = self.linear2_layers[i](torch.relu(self.linear1_layers[i](h)))\n",
    "            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            if self.batchnorm:\n",
    "                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = self.norm2_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            else:\n",
    "                h = self.norm2_layers[i](h) # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "        # Transpose h\n",
    "        h = h.transpose(0,1) # size(h)=(bsz, nb_nodes, dim_emb)\n",
    "        return h, score\n",
    "    \n",
    "\n",
    "class Transformer_decoder_net(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder network based on self-attention transformer\n",
    "    Inputs :  \n",
    "      h of size      (bsz, nb_nodes+1, dim_emb)    batch of input cities\n",
    "    Outputs :  \n",
    "      h of size      (bsz, nb_nodes+1, dim_emb)    batch of encoded cities\n",
    "      score of size  (bsz, nb_nodes+1, nb_nodes+1) batch of attention scores\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_layers, dim_emb, nb_heads, dim_ff, batchnorm):\n",
    "        super(Transformer_decoder_net, self).__init__()\n",
    "        assert dim_emb == nb_heads* (dim_emb//nb_heads) # check if dim_emb is divisible by nb_heads\n",
    "        self.MHA_layers = nn.ModuleList( [nn.MultiheadAttention(dim_emb, nb_heads) for _ in range(nb_layers)] )\n",
    "        self.CRS_layers = nn.ModuleList( [nn.MultiheadAttention(dim_emb, nb_heads) for _ in range(nb_layers)] )\n",
    "\n",
    "        if batchnorm:\n",
    "            self.norm1_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n",
    "            self.norm2_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n",
    "            self.norm3_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n",
    "        else:\n",
    "            self.norm1_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n",
    "            self.norm2_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n",
    "            self.norm3_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n",
    "        \n",
    "        self.linear1_layers = nn.ModuleList( [nn.Linear(dim_emb, dim_ff) for _ in range(nb_layers)] )\n",
    "        self.linear2_layers = nn.ModuleList( [nn.Linear(dim_ff, dim_emb) for _ in range(nb_layers)] )   \n",
    "        self.nb_layers = nb_layers\n",
    "        self.nb_heads = nb_heads\n",
    "        self.batchnorm = batchnorm\n",
    "        \n",
    "    def forward(self, q, k, v):      \n",
    "        # PyTorch nn.MultiheadAttention requires input size (seq_len, bsz, dim_emb) \n",
    "        q = q.transpose(0,1) # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "        k = k.transpose(0,1)\n",
    "        v = v.transpose(0,1)\n",
    "        # L layers\n",
    "        for i in range(self.nb_layers):\n",
    "            q_rc = q # residual connection, size(h_rc)=(nb_nodes, bsz, dim_emb)\n",
    "            q, score = self.MHA_layers[i](q, q, q) # size(h)=(nb_nodes, bsz, dim_emb), size(score)=(bsz, nb_nodes, nb_nodes)\n",
    "            # add residual connection\n",
    "            q = q_rc + q # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            if self.batchnorm:\n",
    "                # Pytorch nn.BatchNorm1d requires input size (bsz, dim, seq_len)\n",
    "                q = q.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                q = self.norm1_layers[i](q)       # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                q = q.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            else:\n",
    "                q = self.norm1_layers[i](q)       # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "\n",
    "            q_rc = q\n",
    "            q, score = self.CRS_layers[i](q, k, v)\n",
    "            q = q_rc + q # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            if self.batchnorm:\n",
    "                # Pytorch nn.BatchNorm1d requires input size (bsz, dim, seq_len)\n",
    "                q = q.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                q = self.norm2_layers[i](q)       # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                q = q.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            else:\n",
    "                q = self.norm2_layers[i](q)       # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            \n",
    "            # feedforward\n",
    "            q_rc = q # residual connection\n",
    "            q = self.linear2_layers[i](torch.relu(self.linear1_layers[i](q)))\n",
    "            q = q_rc + q # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            if self.batchnorm:\n",
    "                q = q.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                q = self.norm3_layers[i](q)       # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                q = q.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            else:\n",
    "                q = self.norm3_layers[i](q) # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "        # Transpose h\n",
    "        q = q.transpose(0,1) # size(h)=(bsz, nb_nodes, dim_emb)\n",
    "        return q, score\n",
    "    \n",
    "    \n",
    "class TSP_net(nn.Module): \n",
    "    \n",
    "    def __init__(self, dim_input_nodes, dim_emb, dim_ff, \n",
    "                 nb_layers_encoder, nb_heads, batchnorm=True):\n",
    "        super(TSP_net, self).__init__()\n",
    "        \n",
    "        self.dim_emb = dim_emb\n",
    "        \n",
    "        # input embedding layer\n",
    "        self.input_emb = nn.Linear(dim_input_nodes, dim_emb)\n",
    "        \n",
    "        # encoder layer\n",
    "        self.encoder = Transformer_encoder_net(nb_layers_encoder, dim_emb, nb_heads, dim_ff, batchnorm)\n",
    "\n",
    "        self.decoder = Transformer_decoder_net(nb_layers_encoder, dim_emb, nb_heads, dim_ff, batchnorm)\n",
    "\n",
    "        self.query_box = nn.Parameter(torch.randn(50, dim_emb))\n",
    "\n",
    "        self.linear_class = nn.Linear(dim_emb, 50)\n",
    "        self.linear_box = nn.Linear(dim_emb, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # input embedding layer\n",
    "        h = self.input_emb(x) # size(h)=(bsz, nb_nodes, dim_emb)\n",
    "        \n",
    "        # encoder layer\n",
    "        h_encoder, _ = self.encoder(h) # size(h)=(bsz, nb_nodes, dim_emb)\n",
    "\n",
    "        h_decoder, _ = self.decoder(self.query_box, h_encoder, h_encoder)\n",
    "\n",
    "        return self.linear_class(h_decoder), self.linear_box(h_decoder)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "model = TSP_net(args.dim_input_nodes, args.dim_emb, args.dim_ff, \n",
    "              args.nb_layers_encoder, args.nb_heads, batchnorm=args.batchnorm)\n",
    "\n",
    "model_baseline = TSP_net(args.dim_input_nodes, args.dim_emb, args.dim_ff, \n",
    "              args.nb_layers_encoder, args.nb_heads, batchnorm=args.batchnorm)\n",
    "\n",
    "# uncomment these lines if trained with multiple GPUs\n",
    "print(torch.cuda.device_count())\n",
    "if torch.cuda.device_count()>1:\n",
    "    model = nn.DataParallel(model)\n",
    "    model_baseline = nn.DataParallel(model_baseline)\n",
    "# uncomment these lines if trained with multiple GPUs\n",
    "\n",
    "optimizer = torch.optim.Adam( model.parameters() , lr = args.lr ) \n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "print(args); print('')\n",
    "\n",
    "# Logs\n",
    "os.system(\"mkdir logs\")\n",
    "time_stamp=datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\")\n",
    "file_name = 'logs'+'/'+time_stamp + \"-n{}\".format(args.nb_nodes) + \"-gpu{}\".format(args.gpu_id) + \".txt\"\n",
    "file = open(file_name,\"w\",1) \n",
    "file.write(time_stamp+'\\n\\n') \n",
    "for arg in vars(args):\n",
    "    file.write(arg)\n",
    "    hyper_param_val=\"={}\".format(getattr(args, arg))\n",
    "    file.write(hyper_param_val)\n",
    "    file.write('\\n')\n",
    "file.write('\\n\\n') \n",
    "plot_performance_train = []\n",
    "plot_performance_baseline = []\n",
    "all_strings = []\n",
    "epoch_ckpt = 0\n",
    "tot_time_ckpt = 0\n",
    "\n",
    "\n",
    "# # Uncomment these lines to re-start training with saved checkpoint\n",
    "# checkpoint_file = \"checkpoint/checkpoint_21-03-01--17-25-00-n50-gpu0.pkl\"\n",
    "# checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "# epoch_ckpt = checkpoint['epoch'] + 1\n",
    "# tot_time_ckpt = checkpoint['tot_time']\n",
    "# plot_performance_train = checkpoint['plot_performance_train']\n",
    "# plot_performance_baseline = checkpoint['plot_performance_baseline']\n",
    "# model_baseline.load_state_dict(checkpoint['model_baseline'])\n",
    "# model.load_state_dict(checkpoint['model'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "# print('Re-start training with saved checkpoint file={:s}\\n  Checkpoint at epoch= {:d} and time={:.3f}min\\n'.format(checkpoint_file,epoch_ckpt-1,tot_time_ckpt/60))\n",
    "# del checkpoint\n",
    "# # Uncomment these lines to re-start training with saved checkpoint\n",
    "\n",
    "\n",
    "class TSPDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.data, self.label = torch.load(data_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return data, label\n",
    "\n",
    "\n",
    "\n",
    "data_path = \"./train_data_50.pth\"\n",
    "\n",
    "dataset = TSPDataset(data_path)\n",
    "dataloader = DataLoader(dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "def custom_loss(output_class, output_box, label_class, label_box):\n",
    "    loss_class = F.cross_entropy(output_class.transpose(1, 2), label_class.squeeze(-1))\n",
    "\n",
    "    loss_box = F.mse_loss(output_box, label_box)\n",
    "\n",
    "    loss = loss_class + loss_box\n",
    "    return loss, loss_class, loss_box\n",
    "\n",
    "###################\n",
    "# Main training loop \n",
    "###################\n",
    "start_training_time = time.time()\n",
    "\n",
    "for epoch in range(0,args.nb_epochs):\n",
    "    \n",
    "    # re-start training with saved checkpoint\n",
    "    epoch += epoch_ckpt\n",
    "\n",
    "    ###################\n",
    "    # Train model for one epoch\n",
    "    ###################\n",
    "    start = time.time()\n",
    "    model.train() \n",
    "\n",
    "    for data, label_class in dataloader:\n",
    "        data = data.to(device)\n",
    "        label_class = label_class.to(device)\n",
    "\n",
    "        output_class, output_box = model(data)\n",
    "\n",
    "        label_box = data.gather(1, label_class.expand(-1, -1, 2))\n",
    "        loss, loss_class, loss_box = custom_loss(output_class, output_box, label_class, label_box)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    time_one_epoch = time.time() - start\n",
    "    time_tot = time.time() - start_training_time + tot_time_ckpt\n",
    "\n",
    "        \n",
    "    ###################\n",
    "    # Evaluate train model and baseline on 10k random TSP instances\n",
    "    ###################\n",
    "    def compute_tsp_length(points):\n",
    "        length = 0.0\n",
    "        for i in range(len(points) - 1):\n",
    "            length += np.linalg.norm(points[i] - points[i+1])\n",
    "        length += np.linalg.norm(points[-1] - points[0])\n",
    "        return length\n",
    "\n",
    "    def evaluate(model, val_dataloader):\n",
    "        total_length = 0.0\n",
    "        total_samples = 0\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, _ in val_dataloader:\n",
    "                data = data.to(device)\n",
    "                output_class, output_box = model(data)\n",
    "\n",
    "                output_class = output_class.cpu().numpy()\n",
    "                output_box = output_box.cpu().numpy()\n",
    "                data = data.cpu().numpy()\n",
    "\n",
    "                for i in range(len(data)):\n",
    "                    cost_matrix = np.linalg.norm(output_box[i] - data[i, :, None, :], axis=2)\n",
    "                    _, col_idx = linear_sum_assignment(cost_matrix)\n",
    "                    matched_points = data[i][col_idx]\n",
    "\n",
    "                    order_probs = torch.nn.functional.softmax(torch.tensor(output_class[i]), dim=-1).numpy()\n",
    "                    order_cost_matrix = -order_probs\n",
    "                    _, order = linear_sum_assignment(order_cost_matrix)\n",
    "\n",
    "                    sorted_points = matched_points[order]\n",
    "\n",
    "                    tsp_length = compute_tsp_length(sorted_points)\n",
    "                    total_length += tsp_length\n",
    "                \n",
    "                total_samples += len(data)\n",
    "\n",
    "        average_length = total_length / total_samples\n",
    "        return average_length\n",
    "\n",
    "    # TODO: evaluate dataloader\n",
    "    evaluate(model, dataloader)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    mean_tour_length_train = 0\n",
    "    mean_tour_length_baseline = 0\n",
    "    for step in range(0,args.nb_batch_eval):\n",
    "\n",
    "        # generate a batch of random tsp instances   \n",
    "        x = torch.rand(args.bsz, args.nb_nodes, args.dim_input_nodes, device=device) \n",
    "\n",
    "        # compute tour for model and baseline\n",
    "        with torch.no_grad():\n",
    "            tour_train, _ = model(x, deterministic=True)\n",
    "            tour_baseline, _ = model_baseline(x, deterministic=True)\n",
    "            \n",
    "        # get the lengths of the tours\n",
    "        L_train = compute_tour_length(x, tour_train)\n",
    "        L_baseline = compute_tour_length(x, tour_baseline)\n",
    "\n",
    "        # L_tr and L_bl are tensors of shape (bsz,). Compute the mean tour length\n",
    "        mean_tour_length_train += L_train.mean().item()\n",
    "        mean_tour_length_baseline += L_baseline.mean().item()\n",
    "\n",
    "    mean_tour_length_train =  mean_tour_length_train/ args.nb_batch_eval\n",
    "    mean_tour_length_baseline =  mean_tour_length_baseline/ args.nb_batch_eval\n",
    "\n",
    "    # evaluate train model and baseline and update if train model is better\n",
    "    update_baseline = mean_tour_length_train+args.tol < mean_tour_length_baseline\n",
    "    if update_baseline:\n",
    "        model_baseline.load_state_dict( model.state_dict() )\n",
    "\n",
    "    # Compute TSPs for small test set\n",
    "    # Note : this can be removed\n",
    "    with torch.no_grad():\n",
    "        tour_baseline, _ = model_baseline(x_1000tsp, deterministic=True)\n",
    "    mean_tour_length_test = compute_tour_length(x_1000tsp, tour_baseline).mean().item()\n",
    "    \n",
    "    # For checkpoint\n",
    "    plot_performance_train.append([ (epoch+1), mean_tour_length_train])\n",
    "    plot_performance_baseline.append([ (epoch+1), mean_tour_length_baseline])\n",
    "        \n",
    "    # Compute optimality gap\n",
    "    if args.nb_nodes==50: gap_train = mean_tour_length_train/5.692- 1.0\n",
    "    elif args.nb_nodes==100: gap_train = mean_tour_length_train/7.765- 1.0\n",
    "    else: gap_train = -1.0\n",
    "    \n",
    "    # Print and save in txt file\n",
    "    mystring_min = 'Epoch: {:d}, epoch time: {:.3f}min, tot time: {:.3f}day, L_train: {:.3f}, L_base: {:.3f}, L_test: {:.3f}, gap_train(%): {:.3f}, update: {}'.format(\n",
    "        epoch, time_one_epoch/60, time_tot/86400, mean_tour_length_train, mean_tour_length_baseline, mean_tour_length_test, 100*gap_train, update_baseline) \n",
    "    print(mystring_min) # Comment if plot display\n",
    "    file.write(mystring_min+'\\n')\n",
    "#     all_strings.append(mystring_min) # Uncomment if plot display\n",
    "#     for string in all_strings: \n",
    "#         print(string)\n",
    "    \n",
    "    # Saving checkpoint\n",
    "    checkpoint_dir = os.path.join(\"checkpoint\")\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'time': time_one_epoch,\n",
    "        'tot_time': time_tot,\n",
    "        'loss': loss.item(),\n",
    "        'TSP_length': [torch.mean(L_train).item(), torch.mean(L_baseline).item(), mean_tour_length_test],\n",
    "        'plot_performance_train': plot_performance_train,\n",
    "        'plot_performance_baseline': plot_performance_baseline,\n",
    "        'mean_tour_length_test': mean_tour_length_test,\n",
    "        'model_baseline': model_baseline.state_dict(),\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        }, '{}.pkl'.format(checkpoint_dir + \"/checkpoint_\" + time_stamp + \"-n{}\".format(args.nb_nodes) + \"-gpu{}\".format(args.gpu_id)))\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
